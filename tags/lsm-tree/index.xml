<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>LSM-tree - Tag - Coding Panda&#39;s Blog</title>
    <link>https://zhiwayzhang.github.io/tags/lsm-tree/</link>
    <description>LSM-tree - Tag - Coding Panda&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator><language>en</language><managingEditor>zhiweizhang@hust.edu.cn (Zhiwei Zhang)</managingEditor>
      <webMaster>zhiweizhang@hust.edu.cn (Zhiwei Zhang)</webMaster><lastBuildDate>Sat, 26 Nov 2022 13:40:59 &#43;0800</lastBuildDate><atom:link href="https://zhiwayzhang.github.io/tags/lsm-tree/" rel="self" type="application/rss+xml" /><item>
  <title>[ATC&#39;20] PinK: High-speed In-storage Key-value Store with Bounded Tails</title>
  <link>https://zhiwayzhang.github.io/posts/pinkkv/</link>
  <pubDate>Sat, 26 Nov 2022 13:40:59 &#43;0800</pubDate>
  <author>Zhiwei Zhang</author>
  <guid>https://zhiwayzhang.github.io/posts/pinkkv/</guid>
  <description><![CDATA[0x00 Everyday English preferable 更可取的
consequently 因此
inevitably 必然的
conventional 常规的、传统的
exacerbates 加剧
deteriorates 恶化
deterministic 确定性
0x01 Intro 本文主要提出了Pink，基于LSM tree的KV-SSD，主要通过避免使用布隆过滤器，而是使用少量DRAM来进行优化
传统的KV-SSD主要通过在控制器的DRAM中维护一个hash table来寻址，受到DRAM的容量限制，超出容量的部分会暂时存放在闪存中，因此在寻址时带来了访问闪存的额外开销，同时当发生哈希碰撞时，可能会操作多个闪存，造成了大量不可预测的开销
单纯使用LSM做为替换的话，可以减少DRAM的存储，但是存在一些性能问题：
尾延迟：很多LSM-tree使用布隆过滤器来快速检索，可靠性差，存在尾延迟问题 写放大：由于LSM对KV索引的排序和合并操作，带来了很多对闪存额外的访问，还增大了FTL进行GC的负担 布隆过滤器的重建和KV排序：消耗了大量的CPU资源，带来I/O性能的大幅下降 本文提出了一种基于LSM-tree的KV存储引擎-PinK，解决了上述三个问题。PinK使用了四种技术。
PinK的核心是level pinning，将固定在LSM-tree最顶层的KV索引固定到DRAM中
由于部分level固定在DRAM中，因此可以直接进行compaction，无需占用闪存的I/O，被固定的索引通过电容进行保护，因此也不需要定期进行刷新，这里要注意作者使用DRAM容量很小，使用电容足以保证持久化
GC的主要I/O开销来自对LSM-tree索引的更新，Pink通过延迟LSM-tree中索引更新到compaction阶段来减少GC的I/O开销
在SSD控制器和NAND芯片之间添加比较器，PinK在读取KV对象时执行KV排序，完全消除了compaction的CPU成本
0x02 Bg 了解一些有关NAND闪存SSD、KV-SSD、Hash-based KV-SSD、LSM-Tree-based KV-SSD的现状，并对Hash和LSM-tree进行比较
作者对LSM-tree的设计，L0位于DRAM中，并作为write buffer，其余各层存储在闪存中
0x03 Design Pink有四个主要的数据结构
位于DRAM中的level lists和Skiplist
位于闪存中的meta segments和data segments
在LSM-tree KV 文件系统方面，作者主要参考了WiscKey FAST'16，取代FTL进行GC、索引和磨损均衡
Skiplist Skiplist作为LSM-tree中的L0，起到类似write buffer的作用，暂时保存KV对象，Skiplist中的对象为：&lt;key size, key, value size, value&gt;
当Skiplist满时，会将缓存的对象以meta segment和data segment的形式刷新到L1中，在L1和更低的level中，Key和Value将被分离存储到meta/data segment中，data segment中存储value、key和key size用于GC
Level list 用于跟踪闪存中每个level的meta segment]]></description>
</item>
<item>
  <title>[OSDI&#39;21] Modernizing File System through In-Storage Indexing</title>
  <link>https://zhiwayzhang.github.io/posts/modernfilesystem/</link>
  <pubDate>Sat, 29 Oct 2022 16:48:32 &#43;0800</pubDate>
  <author>Zhiwei Zhang</author>
  <guid>https://zhiwayzhang.github.io/posts/modernfilesystem/</guid>
  <description><![CDATA[Questions 核心思想部分需要再思考和梳理下，
为什么采用 KV SSD 替代传统 block SSD 能够解决上述问题？ 其中，利用了 KV SSD 的什么特性？ 对文件系统哪些地方做了什么以优化？ 论文试图解决的问题：
随着存储设备的不断发展，存储设备的性能越来越高，但当前操作系统内核的文件系统在一些操作上并不能够充分利用如今存储设备的性能。
文件系统在执行数据写入时，需要执行大量操作维护元数据、进行硬盘的空间管理、维护文件系统的一致性，工作量大。
核心思想：
使用Key-Value存储接口取代传统的快设备接口。
具体实现：
提出Kevin，分为Kevin=KevinFS + KevinSSD
KevinFS
维护文件和目录到KV对象的映射关系 将POSIX系统调用转译成KV操作指令 保证KV-SSD的一致性 KevinSSD
在存储设备中索引KV对象 对多个KV对象提供事务操作 0x00 Intro Kevin避免了大量元数据的维护带来的I/O放大
不需要日志即可完成崩溃一致性的维护
可以抵御文件分段后造成的性能下降
存储的文件块通过LSM进行分部排序和索引
0x01 BG &amp;&amp; Related Work 传统块设备 提供块粒度（512B or 4KB）的访问
HDD通过维护一个间接表来处理坏块
基于闪存的SSD通过FTL来维护逻辑块到物理地址的映射索引表，以便在异地更新的NAND上模拟可重写介质并且排除坏块。
现有研究缓解了I/O调度、文件碎片化、日志相关问题，没能消除元数据的修改带来的I/O流量
DevFS实现了在存储设备内部的文件系统，直接将接口暴露给应用，调用时不用发生Trap，对于元数据的维护都在存储设备端执行，移除了I/O 栈减少了通信接口的开销。缺点是需要大量的DRAM和多核心的CPU、能提供的功能有限，还限制了快照、重复数据删除等文件系统高级功能的实现。
KV存储可以高效处理元数据和小文件的写入
LSM-Tree LSM Tree有多级，包括$L_1,L_2,&hellip;,L_{h-1},L_{h}$，h是树的高度，对于各级的大小有如下关系，$Size(L_{i+1})&gt;=T*Size(L_i)$
每层都有按Key排序的唯一KV对象。各层之间的Key范围可能会出现重叠。
KV对象首先写入DRAM中的Memtable，当Memtable不为空时，缓存的KV对象将刷新到L1中进行持久化，当L1不为空时，KV对象刷新到L2中，依此类推。在刷新过程中会执行压缩操作来对两层之间的KV对象进行合并和排序，在排序后写回磁盘中。
为了改善压缩操作的I/O开销，可以将所有的value存储在value log中，在LSM tree中只保存value指针，存储&lt;key, value pointer&gt;形式。对于失效的value要考虑垃圾回收问题。
在对KV对象进行检索时，可能需要在多级进行查找，当在Li不匹配时，查找Li+1。为了减少多级查找的读取，可以使用布隆过滤器进行优化，当检索到目标KV对象时，LSM tree将会返回相应的value，KV分离存储的情况下，将会额外去读一次value log。
0x02 Architecture KEVIN分为两个部分
KEVINFS：维护文件、目录到KV对象映射的文件系统
KEVINSSD：索引KV对象到闪存的LSM-tree
KV Command 支持多种KV指令，同时支持事务]]></description>
</item>
</channel>
</rss>
